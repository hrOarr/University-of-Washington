{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SFrames to do some feature engineering.\n",
    "# Modify the decision trees to incorporate weights.\n",
    "# Implement Adaboost ensembling.\n",
    "# Use your implementation of Adaboost to train a boosted decision stump ensemble.\n",
    "# Evaluate the effect of boosting (adding more decision stumps) on performance of the model.\n",
    "# Explore the robustness of Adaboost to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphlab\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to registrar@juniv.edu and will expire on May 03, 2021.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\my\\AppData\\Local\\Temp\\graphlab_server_1589449014.log.0\n"
     ]
    }
   ],
   "source": [
    "loans = graphlab.SFrame('lending-club-data.sframe/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the target and the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans.remove_column('bad_loans')\n",
    "target = 'safe_loans'\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample dataset to make sure classes are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of safe loans                 : 0.502236174422\n",
      "Percentage of risky loans                : 0.497763825578\n",
      "Total number of loans in our new dataset : 46508\n"
     ]
    }
   ],
   "source": [
    "safe_loans_raw = loans[loans[target] == 1]\n",
    "risky_loans_raw = loans[loans[target] == -1]\n",
    "\n",
    "# Undersample the safe loans.\n",
    "percentage = len(risky_loans_raw)/float(len(safe_loans_raw))\n",
    "risky_loans = risky_loans_raw\n",
    "safe_loans = safe_loans_raw.sample(percentage, seed=1)\n",
    "loans_data = risky_loans_raw.append(safe_loans)\n",
    "\n",
    "print \"Percentage of safe loans                 :\", len(safe_loans) / float(len(loans_data))\n",
    "print \"Percentage of risky loans                :\", len(risky_loans) / float(len(loans_data))\n",
    "print \"Total number of loans in our new dataset :\", len(loans_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform categorical data into binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_data = risky_loans.append(safe_loans)\n",
    "for feature in features:\n",
    "    loans_data_one_hot_encoded = loans_data[feature].apply(lambda x: {x: 1})    \n",
    "    loans_data_unpacked = loans_data_one_hot_encoded.unpack(column_name_prefix=feature)\n",
    "    \n",
    "    # Change None's to 0's\n",
    "    for column in loans_data_unpacked.column_names():\n",
    "        loans_data_unpacked[column] = loans_data_unpacked[column].fillna(0)\n",
    "\n",
    "    loans_data.remove_column(feature)\n",
    "    loans_data.add_columns(loans_data_unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grade.A',\n",
       " 'grade.B',\n",
       " 'grade.C',\n",
       " 'grade.D',\n",
       " 'grade.E',\n",
       " 'grade.F',\n",
       " 'grade.G',\n",
       " 'term. 36 months',\n",
       " 'term. 60 months',\n",
       " 'home_ownership.MORTGAGE',\n",
       " 'home_ownership.OTHER',\n",
       " 'home_ownership.OWN',\n",
       " 'home_ownership.RENT',\n",
       " 'emp_length.1 year',\n",
       " 'emp_length.10+ years',\n",
       " 'emp_length.2 years',\n",
       " 'emp_length.3 years',\n",
       " 'emp_length.4 years',\n",
       " 'emp_length.5 years',\n",
       " 'emp_length.6 years',\n",
       " 'emp_length.7 years',\n",
       " 'emp_length.8 years',\n",
       " 'emp_length.9 years',\n",
       " 'emp_length.< 1 year',\n",
       " 'emp_length.n/a']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = loans_data.column_names()\n",
    "features.remove('safe_loans')  # Remove the response variable\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = loans_data.random_split(0.8, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_node_weighted_mistakes(labels_in_node, data_weights):\n",
    "    # Sum the weights of all entries with label +1\n",
    "    total_weight_positive = sum(data_weights[labels_in_node == +1])\n",
    "    \n",
    "    # Weight of mistakes for predicting all -1's is equal to the sum above\n",
    "    ### YOUR CODE HERE\n",
    "    weighted_mistakes_all_negative = total_weight_positive\n",
    "    \n",
    "    # Sum the weights of all entries with label -1\n",
    "    ### YOUR CODE HERE\n",
    "    total_weight_negative = sum(data_weights[labels_in_node == -1])\n",
    "    \n",
    "    # Weight of mistakes for predicting all +1's is equal to the sum above\n",
    "    ### YOUR CODE HERE\n",
    "    weighted_mistakes_all_positive = total_weight_negative\n",
    "    \n",
    "    # Return the tuple (weight, class_label) representing the lower of the two weights\n",
    "    #    class_label should be an integer of value +1 or -1.\n",
    "    # If the two weights are identical, return (weighted_mistakes_all_positive,+1)\n",
    "    ### YOUR CODE HERE\n",
    "    if weighted_mistakes_all_positive <= weighted_mistakes_all_negative:        \n",
    "        return (weighted_mistakes_all_positive, +1)\n",
    "    else:        \n",
    "        return (weighted_mistakes_all_negative, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "example_labels = graphlab.SArray([-1, -1, 1, 1, 1])\n",
    "example_data_weights = graphlab.SArray([1., 2., .5, 1., 1.])\n",
    "if intermediate_node_weighted_mistakes(example_labels, example_data_weights) == (2.5, -1):\n",
    "    print 'Test passed!'\n",
    "else:\n",
    "    print 'Test failed... try again!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n"
     ]
    }
   ],
   "source": [
    "example_labels = graphlab.SArray([1, 1, 1, 1, 1])\n",
    "example_data_weights = graphlab.SArray([1., 2., .5, 1., 1.])\n",
    "print intermediate_node_weighted_mistakes(example_labels, example_data_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to pick best feature to split on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the data is identical in each feature, this function should return None\n",
    "\n",
    "def best_splitting_feature(data, features, target, data_weights):\n",
    "    \n",
    "    # These variables will keep track of the best feature and the corresponding error\n",
    "    best_feature = None\n",
    "    best_error = float('+inf') \n",
    "    num_points = float(len(data))\n",
    "\n",
    "    # Loop through each feature to consider splitting on that feature\n",
    "    for feature in features:\n",
    "        \n",
    "        # The left split will have all data points where the feature value is 0\n",
    "        # The right split will have all data points where the feature value is 1\n",
    "        left_split = data[data[feature] == 0]\n",
    "        right_split = data[data[feature] == 1]\n",
    "        \n",
    "        # Apply the same filtering to data_weights to create left_data_weights, right_data_weights\n",
    "        ## YOUR CODE HERE\n",
    "        left_data_weights = data_weights[data[feature] == 0]\n",
    "        right_data_weights = data_weights[data[feature] == 1]\n",
    "                    \n",
    "        # DIFFERENT HERE\n",
    "        # Calculate the weight of mistakes for left and right sides\n",
    "        ## YOUR CODE HERE\n",
    "        left_weighted_mistakes, left_class = intermediate_node_weighted_mistakes(left_split[target], left_data_weights)\n",
    "        right_weighted_mistakes, right_class = intermediate_node_weighted_mistakes(right_split[target], right_data_weights)\n",
    "        \n",
    "        # DIFFERENT HERE\n",
    "        # Compute weighted error by computing\n",
    "        #  ( [weight of mistakes (left)] + [weight of mistakes (right)] ) / [total weight of all data points]\n",
    "        ## YOUR CODE HERE\n",
    "        error = (left_weighted_mistakes + right_weighted_mistakes)/(sum(left_data_weights) + sum(right_data_weights))\n",
    "        \n",
    "        # If this is the best error we have found so far, store the feature and the error\n",
    "        if error < best_error:\n",
    "            best_feature = feature\n",
    "            best_error = error\n",
    "    \n",
    "    # Return the best feature we found\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "example_data_weights = graphlab.SArray(len(train_data)* [1.5])\n",
    "if best_splitting_feature(train_data, features, target, example_data_weights) == 'term. 36 months':\n",
    "    print 'Test passed!'\n",
    "else:\n",
    "    print 'Test failed... try again!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# { \n",
    "#    'is_leaf'            : True/False.\n",
    "#    'prediction'         : Prediction at the leaf node.\n",
    "#    'left'               : (dictionary corresponding to the left tree).\n",
    "#    'right'              : (dictionary corresponding to the right tree).\n",
    "#    'features_remaining' : List of features that are posible splits.\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(target_values, data_weights):\n",
    "    \n",
    "    # Create a leaf node\n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'is_leaf': True}\n",
    "    \n",
    "    # Computed weight of mistakes.\n",
    "    weighted_error, best_class = intermediate_node_weighted_mistakes(target_values, data_weights)\n",
    "    # Store the predicted class (1 or -1) in leaf['prediction']\n",
    "    leaf['prediction'] = best_class\n",
    "    \n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We provide a function that learns a weighted decision tree recursively and implements 3 stopping conditions:\n",
    "\n",
    "# All data points in a node are from the same class.\n",
    "# No more features to split on.\n",
    "# Stop growing the tree when the tree depth reaches max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_decision_tree_create(data, features, target, data_weights, current_depth = 1, max_depth = 10):\n",
    "    remaining_features = features[:] # Make a copy of the features.\n",
    "    target_values = data[target]\n",
    "    print \"--------------------------------------------------------------------\"\n",
    "    print \"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values))\n",
    "    \n",
    "    # Stopping condition 1. Error is 0.\n",
    "    if intermediate_node_weighted_mistakes(target_values, data_weights)[0] <= 1e-15:\n",
    "        print \"Stopping condition 1 reached.\"                \n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    # Stopping condition 2. No more features.\n",
    "    if remaining_features == []:\n",
    "        print \"Stopping condition 2 reached.\"                \n",
    "        return create_leaf(target_values, data_weights)    \n",
    "    \n",
    "    # Additional stopping condition (limit tree depth)\n",
    "    if current_depth > max_depth:\n",
    "        print \"Reached maximum depth. Stopping for now.\"\n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    # If all the datapoints are the same, splitting_feature will be None. Create a leaf\n",
    "    splitting_feature = best_splitting_feature(data, features, target, data_weights)\n",
    "    remaining_features.remove(splitting_feature)\n",
    "        \n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]\n",
    "    \n",
    "    left_data_weights = data_weights[data[splitting_feature] == 0]\n",
    "    right_data_weights = data_weights[data[splitting_feature] == 1]\n",
    "    \n",
    "    print \"Split on feature %s. (%s, %s)\" % (\\\n",
    "              splitting_feature, len(left_split), len(right_split))\n",
    "    \n",
    "    # Create a leaf node if the split is \"perfect\"\n",
    "    if len(left_split) == len(data):\n",
    "        print \"Creating leaf node.\"\n",
    "        return create_leaf(left_split[target], data_weights)\n",
    "    if len(right_split) == len(data):\n",
    "        print \"Creating leaf node.\"\n",
    "        return create_leaf(right_split[target], data_weights)\n",
    "    \n",
    "    # Repeat (recurse) on left and right subtrees\n",
    "    left_tree = weighted_decision_tree_create(\n",
    "        left_split, remaining_features, target, left_data_weights, current_depth + 1, max_depth)\n",
    "    right_tree = weighted_decision_tree_create(\n",
    "        right_split, remaining_features, target, right_data_weights, current_depth + 1, max_depth)\n",
    "    \n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9223 data points).\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (9122 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (101 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28001 data points).\n",
      "Split on feature grade.D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (23300 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (4701 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "example_data_weights = graphlab.SArray([1.0 for i in range(len(train_data))])\n",
    "small_data_decision_tree = weighted_decision_tree_create(train_data, features, target,\n",
    "                                        example_data_weights, max_depth=2)\n",
    "if count_nodes(small_data_decision_tree) == 7:\n",
    "    print 'Test passed!'\n",
    "else:\n",
    "    print 'Test failed... try again!'\n",
    "    print 'Number of nodes found:', count_nodes(small_data_decision_tree)\n",
    "    print 'Number of nodes that should be there: 7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_leaf': False,\n",
       " 'left': {'is_leaf': False,\n",
       "  'left': {'is_leaf': True, 'prediction': -1, 'splitting_feature': None},\n",
       "  'prediction': None,\n",
       "  'right': {'is_leaf': True, 'prediction': 1, 'splitting_feature': None},\n",
       "  'splitting_feature': 'grade.A'},\n",
       " 'prediction': None,\n",
       " 'right': {'is_leaf': False,\n",
       "  'left': {'is_leaf': True, 'prediction': 1, 'splitting_feature': None},\n",
       "  'prediction': None,\n",
       "  'right': {'is_leaf': True, 'prediction': -1, 'splitting_feature': None},\n",
       "  'splitting_feature': 'grade.D'},\n",
       " 'splitting_feature': 'term. 36 months'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data_decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with a weighted decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate = False):   \n",
    "    # If the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        if annotate: \n",
    "            print \"At leaf, predicting %s\" % tree['prediction']\n",
    "        return tree['prediction'] \n",
    "    else:\n",
    "        # Split on feature.\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        if annotate: \n",
    "            print \"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value)\n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree['left'], x, annotate)\n",
    "        else:\n",
    "            return classify(tree['right'], x, annotate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data):\n",
    "    # Apply the classify(tree, x) to each row in your data\n",
    "    prediction = data.apply(lambda x: classify(tree, x))\n",
    "    \n",
    "    # Once you've made the predictions, calculate the classification error\n",
    "    return (prediction != data[target]).sum() / float(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3981042654028436"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(small_data_decision_tree, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Training a weighted decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we only care about making good predictions for the first 10 and last 10 items in train_data, we assign weights:\n",
    "\n",
    "# 1 to the last 10 items\n",
    "# 1 to the first 10 items\n",
    "# and 0 to the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature home_ownership.RENT. (20514, 16710)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (20514 data points).\n",
      "Split on feature grade.F. (19613, 901)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (19613 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (901 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (16710 data points).\n",
      "Split on feature grade.D. (13315, 3395)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (13315 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3395 data points).\n",
      "Stopping condition 1 reached.\n"
     ]
    }
   ],
   "source": [
    "# Assign weights\n",
    "example_data_weights = graphlab.SArray([1.] * 10 + [0.]*(len(train_data) - 20) + [1.] * 10)\n",
    "\n",
    "# Train a weighted decision tree model.\n",
    "small_data_decision_tree_subset_20 = weighted_decision_tree_create(train_data, features, target,\n",
    "                         example_data_weights, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_20 = train_data.head(10).append(train_data.tail(10))\n",
    "evaluate_classification_error(small_data_decision_tree_subset_20, subset_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48124865678057166"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(small_data_decision_tree_subset_20, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing your own Adaboost (on decision stumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "from math import exp\n",
    "\n",
    "def adaboost_with_tree_stumps(data, features, target, num_tree_stumps):\n",
    "    # start with unweighted data\n",
    "    alpha = graphlab.SArray([1.]*len(data))\n",
    "    weights = []\n",
    "    tree_stumps = []\n",
    "    target_values = data[target]\n",
    "    \n",
    "    for t in xrange(num_tree_stumps):\n",
    "        print '====================================================='\n",
    "        print 'Adaboost Iteration %d' % t\n",
    "        print '====================================================='        \n",
    "        # Learn a weighted decision tree stump. Use max_depth=1\n",
    "        tree_stump = weighted_decision_tree_create(data, features, target, data_weights=alpha, max_depth=1)\n",
    "        tree_stumps.append(tree_stump)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = data.apply(lambda x: classify(tree_stump, x))\n",
    "        \n",
    "        # Produce a Boolean array indicating whether\n",
    "        # each data point was correctly classified\n",
    "        is_correct = predictions == target_values\n",
    "        is_wrong   = predictions != target_values\n",
    "        \n",
    "        # Compute weighted error\n",
    "        # YOUR CODE HERE\n",
    "        weighted_error = sum(alpha[is_wrong])/sum(alpha)\n",
    "        \n",
    "        # Compute model coefficient using weighted error\n",
    "        # YOUR CODE HERE\n",
    "        weight = 1./2. * log((1 - weighted_error)/weighted_error)\n",
    "        weights.append(weight)\n",
    "        \n",
    "        # Adjust weights on data point\n",
    "        adjustment = is_correct.apply(lambda is_correct : exp(-weight) if is_correct else exp(weight))\n",
    "        \n",
    "        # Scale alpha by multiplying by adjustment \n",
    "        # Then normalize data points weights\n",
    "        ## YOUR CODE HERE \n",
    "        alpha = (alpha * adjustment)/float(sum(alpha))\n",
    "\n",
    "    return weights, tree_stumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking your Adaboost code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9223 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28001 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "stump_weights, tree_stumps = adaboost_with_tree_stumps(train_data, features, target, num_tree_stumps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stump(tree):\n",
    "    split_name = tree['splitting_feature'] # split_name is something like 'term. 36 months'\n",
    "    if split_name is None:\n",
    "        print \"(leaf, label: %s)\" % tree['prediction']\n",
    "        return None\n",
    "    split_feature, split_value = split_name.split('.')\n",
    "    print '                       root'\n",
    "    print '         |---------------|----------------|'\n",
    "    print '         |                                |'\n",
    "    print '         |                                |'\n",
    "    print '         |                                |'\n",
    "    print '  [{0} == 0]{1}[{0} == 1]    '.format(split_name, ' '*(27-len(split_name)))\n",
    "    print '         |                                |'\n",
    "    print '         |                                |'\n",
    "    print '         |                                |'\n",
    "    print '    (%s)                 (%s)' \\\n",
    "        % (('leaf, label: ' + str(tree['left']['prediction']) if tree['left']['is_leaf'] else 'subtree'),\n",
    "           ('leaf, label: ' + str(tree['right']['prediction']) if tree['right']['is_leaf'] else 'subtree'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       root\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [term. 36 months == 0]            [term. 36 months == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (leaf, label: -1)                 (leaf, label: 1)\n"
     ]
    }
   ],
   "source": [
    "print_stump(tree_stumps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       root\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [grade.A == 0]                    [grade.A == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (leaf, label: -1)                 (leaf, label: 1)\n"
     ]
    }
   ],
   "source": [
    "print_stump(tree_stumps[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15802933659263743, 0.17682363293605327]\n"
     ]
    }
   ],
   "source": [
    "print stump_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a boosted ensemble of 10 stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9223 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28001 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 2\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.D. (30465, 6759)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30465 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6759 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 3\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature home_ownership.MORTGAGE. (19846, 17378)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (19846 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (17378 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 4\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.B. (26858, 10366)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26858 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10366 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 5\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.E. (33815, 3409)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33815 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3409 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 6\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 7\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 8\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 9\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35781 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1443 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "stump_weights, tree_stumps = adaboost_with_tree_stumps(train_data, features, \n",
    "                                target, num_tree_stumps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to do the following things:\n",
    "\n",
    "# Compute the predictions $f_t(x)$ using the $t$-th decision tree\n",
    "# Compute $\\hat{w}_t f_t(x)$ by multiplying the stump_weights with the predictions $f_t(x)$ from the decision trees\n",
    "# Sum the weighted predictions over each stump in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_adaboost(stump_weights, tree_stumps, data):\n",
    "    scores = graphlab.SArray([0.]*len(data))\n",
    "    \n",
    "    for i, tree_stump in enumerate(tree_stumps):\n",
    "        predictions = data.apply(lambda x: classify(tree_stump, x))\n",
    "        \n",
    "        # Accumulate predictions on scores array\n",
    "        # YOUR CODE HERE\n",
    "        scores += (stump_weights[i] * predictions)\n",
    "        \n",
    "    return scores.apply(lambda score : +1 if score > 0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 10-component ensemble = 0.620314519604\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_adaboost(stump_weights, tree_stumps, test_data)\n",
    "accuracy = graphlab.evaluation.accuracy(test_data[target], predictions)\n",
    "print 'Accuracy of 10-component ensemble = %s' % accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15802933659263743,\n",
       " 0.17682363293605327,\n",
       " 0.09311888971195705,\n",
       " 0.0728888552581495,\n",
       " 0.06706306914131716,\n",
       " 0.06456916961613322,\n",
       " 0.05456055779221647,\n",
       " 0.04351093673354489,\n",
       " 0.028988711500059067,\n",
       " 0.0259625096913776]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stump_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9223 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28001 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 2\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.D. (30465, 6759)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30465 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6759 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 3\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature home_ownership.MORTGAGE. (19846, 17378)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (19846 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (17378 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 4\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.B. (26858, 10366)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26858 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10366 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 5\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.E. (33815, 3409)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33815 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3409 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 6\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 7\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 8\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 9\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35781 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1443 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 10\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.D. (30465, 6759)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30465 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6759 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 11\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.B. (26858, 10366)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26858 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10366 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 12\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35781 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1443 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 13\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length.4 years. (34593, 2631)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (34593 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (2631 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 14\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35781 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1443 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 15\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.C. (27812, 9412)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (27812 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9412 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 16\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 17\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 18\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9223 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28001 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 19\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.B. (26858, 10366)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26858 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10366 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 20\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35781 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1443 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 21\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.D. (30465, 6759)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30465 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6759 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 22\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 23\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 24\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35781 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1443 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 25\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length.2 years. (33652, 3572)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33652 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3572 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 26\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 27\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature home_ownership.OWN. (34149, 3075)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (34149 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3075 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 28\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length.n/a. (35781, 1443)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35781 data points).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1443 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 29\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade.C. (27812, 9412)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (27812 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9412 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "# this may take a while... \n",
    "stump_weights, tree_stumps = adaboost_with_tree_stumps(train_data, \n",
    "                                 features, target, num_tree_stumps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing training error at the end of each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, training error = 0.421636578551\n",
      "Iteration 2, training error = 0.433430045132\n",
      "Iteration 3, training error = 0.400037610144\n",
      "Iteration 4, training error = 0.400037610144\n",
      "Iteration 5, training error = 0.384724908661\n",
      "Iteration 6, training error = 0.384617451107\n",
      "Iteration 7, training error = 0.382763808296\n",
      "Iteration 8, training error = 0.384617451107\n",
      "Iteration 9, training error = 0.382763808296\n",
      "Iteration 10, training error = 0.384483129164\n",
      "Iteration 11, training error = 0.382736943907\n",
      "Iteration 12, training error = 0.381447453256\n",
      "Iteration 13, training error = 0.381528046422\n",
      "Iteration 14, training error = 0.380560928433\n",
      "Iteration 15, training error = 0.380507199656\n",
      "Iteration 16, training error = 0.378223726628\n",
      "Iteration 17, training error = 0.378277455405\n",
      "Iteration 18, training error = 0.378411777348\n",
      "Iteration 19, training error = 0.378062540297\n",
      "Iteration 20, training error = 0.378761014399\n",
      "Iteration 21, training error = 0.379566946056\n",
      "Iteration 22, training error = 0.378895336342\n",
      "Iteration 23, training error = 0.378895336342\n",
      "Iteration 24, training error = 0.378761014399\n",
      "Iteration 25, training error = 0.378895336342\n",
      "Iteration 26, training error = 0.378975929508\n",
      "Iteration 27, training error = 0.379110251451\n",
      "Iteration 28, training error = 0.378922200731\n",
      "Iteration 29, training error = 0.379029658285\n",
      "Iteration 30, training error = 0.378734150011\n"
     ]
    }
   ],
   "source": [
    "error_all = []\n",
    "for n in xrange(1, 31):\n",
    "    predictions = predict_adaboost(stump_weights[:n], tree_stumps[:n], train_data)\n",
    "    error = 1.0 - graphlab.evaluation.accuracy(train_data[target], predictions)\n",
    "    error_all.append(error)\n",
    "    print \"Iteration %s, training error = %s\" % (n, error_all[n-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training error vs number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = 7, 5\n",
    "plt.plot(range(1,31), error_all, '-', linewidth=4.0, label='Training error')\n",
    "plt.title('Performance of Adaboost ensemble')\n",
    "plt.xlabel('# of iterations')\n",
    "plt.ylabel('Classification error')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, test error = 0.42330891857\n",
      "Iteration 2, test error = 0.428479103835\n",
      "Iteration 3, test error = 0.398104265403\n",
      "Iteration 4, test error = 0.398104265403\n",
      "Iteration 5, test error = 0.379900904782\n",
      "Iteration 6, test error = 0.380008616975\n",
      "Iteration 7, test error = 0.379254631624\n",
      "Iteration 8, test error = 0.380008616975\n",
      "Iteration 9, test error = 0.379254631624\n",
      "Iteration 10, test error = 0.379685480396\n",
      "Iteration 11, test error = 0.379254631624\n",
      "Iteration 12, test error = 0.377962085308\n",
      "Iteration 13, test error = 0.379254631624\n",
      "Iteration 14, test error = 0.377854373115\n",
      "Iteration 15, test error = 0.378500646273\n",
      "Iteration 16, test error = 0.377854373115\n",
      "Iteration 17, test error = 0.377962085308\n",
      "Iteration 18, test error = 0.377854373115\n",
      "Iteration 19, test error = 0.378177509694\n",
      "Iteration 20, test error = 0.376884963378\n",
      "Iteration 21, test error = 0.377531236536\n",
      "Iteration 22, test error = 0.376777251185\n",
      "Iteration 23, test error = 0.376777251185\n",
      "Iteration 24, test error = 0.376884963378\n",
      "Iteration 25, test error = 0.376777251185\n",
      "Iteration 26, test error = 0.376561826799\n",
      "Iteration 27, test error = 0.376454114606\n",
      "Iteration 28, test error = 0.376992675571\n",
      "Iteration 29, test error = 0.376777251185\n",
      "Iteration 30, test error = 0.376777251185\n"
     ]
    }
   ],
   "source": [
    "test_error_all = []\n",
    "for n in xrange(1, 31):\n",
    "    predictions = predict_adaboost(stump_weights[:n], tree_stumps[:n], test_data)\n",
    "    error = 1.0 - graphlab.evaluation.accuracy(test_data[target], predictions)\n",
    "    test_error_all.append(error)\n",
    "    print \"Iteration %s, test error = %s\" % (n, test_error_all[n-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize both the training and test errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = 7, 5\n",
    "plt.plot(range(1,31), error_all, '-', linewidth=4.0, label='Training error')\n",
    "plt.plot(range(1,31), test_error_all, '-', linewidth=4.0, label='Test error')\n",
    "\n",
    "plt.title('Performance of Adaboost ensemble')\n",
    "plt.xlabel('# of iterations')\n",
    "plt.ylabel('Classification error')\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
